{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a18a939",
   "metadata": {},
   "source": [
    "# TRACO reference solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4540624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:40:20.101937: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 20:40:20.254057: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-24 20:40:20.807873: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /data/du92wufe/.local/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-24 20:40:20.807915: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /data/du92wufe/.local/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-24 20:40:20.807919: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization, Concatenate, Reshape, GlobalAveragePooling2D, UpSampling2D, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from segmentation_models.metrics import iou_score\n",
    "from segmentation_models.losses import dice_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2bd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path where the training data is located\n",
    "path_training_vids = Path(\"training\")\n",
    "\n",
    "# Downsample the input frames to a fixed target_shape\n",
    "target_shape = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65097154",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_train_videos(path):\n",
    "    \"\"\"\n",
    "    This function returns all trainings videos and the annotations as binary masks (1 at the positions where a Hexbug is located).\n",
    "    All frames are resized and normalized. \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for vid in os.listdir(path):\n",
    "        path = Path(path)\n",
    "        if \".mp4\" in vid:\n",
    "            with open(path / vid.replace(\"mp4\", \"traco\")) as f:\n",
    "                annotations = json.load(f)['rois']\n",
    "            \n",
    "            cap = cv2.VideoCapture(str(path / vid))\n",
    "            ret, frame = cap.read()     \n",
    "            org_shape = frame.shape\n",
    "            \n",
    "            z = 0  # frame counter\n",
    "            while ret:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                mask_frame = np.zeros(shape=target_shape)\n",
    "                for annot in annotations:\n",
    "                    if annot['z'] == z: \n",
    "                        # Get pos and scale it down to fit the target_shape\n",
    "                        pos = annot['pos']\n",
    "                        pos[0] = pos[0] * target_shape[0] // org_shape[1]\n",
    "                        pos[1] = pos[1] * target_shape[1] // org_shape[0]\n",
    "                        \n",
    "                        # Set the position if the Hexbug in the binary mask to 1\n",
    "                        try:\n",
    "                            mask_frame[int(pos[1]), int(pos[0])] = 1\n",
    "                        except:\n",
    "                            # IndexOutOfRange error sometimes occurs because of the downsampling of the frames\n",
    "                            mask_frame[int(pos[1]) - 1, int(pos[0]) - 1] = 1\n",
    "                        \n",
    "                # Resize the frame to the target size using bilinear interpolation\n",
    "                resized_frame = cv2.resize(frame, target_shape, interpolation=cv2.INTER_LINEAR)\n",
    "                \n",
    "                # Normalize to zero mean and unit variance\n",
    "                normalized_frame = (resized_frame.astype('float32') / 255.0 - 0.5) / 0.5\n",
    "                \n",
    "                # Append to lists\n",
    "                X.append(normalized_frame)\n",
    "                Y.append(mask_frame) \n",
    "                \n",
    "                ret, frame = cap.read()  # read next frame\n",
    "                z += 1  # increase frame counter\n",
    "                \n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443b825",
   "metadata": {},
   "source": [
    "## Create and train U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e7f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, num_filters):\n",
    "    x = Conv2D(filters=num_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=num_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_Unet(filters=16, num_classes=1):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(target_shape[0], target_shape[1], 3))\n",
    "    \n",
    "    # Encoder\n",
    "    e1 = conv_block(inputs, filters)\n",
    "    p1 = MaxPool2D((2, 2))(e1)\n",
    "    \n",
    "    e2 = conv_block(p1, filters * 2)\n",
    "    p2 = MaxPool2D((2, 2))(e2)\n",
    "    \n",
    "    e3 = conv_block(p2, filters * 4)\n",
    "    p3 = MaxPool2D((2, 2))(e3)\n",
    "    \n",
    "    e4 = conv_block(p3, filters * 8)\n",
    "    p4 = MaxPool2D((2, 2))(e4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    b1 = conv_block(p4, filters * 16)\n",
    "    \n",
    "    # Decoder\n",
    "    d1 = UpSampling2D()(b1)\n",
    "    d1 = Concatenate()([d1, e4])\n",
    "    d1 = conv_block(d1, filters * 8)\n",
    "    \n",
    "    d2 = UpSampling2D()(d1)\n",
    "    d2 = Concatenate()([d2, e3])\n",
    "    d2 = conv_block(d2, filters * 4)\n",
    "    \n",
    "    d3 = UpSampling2D()(d2)\n",
    "    d3 = Concatenate()([d3, e2])\n",
    "    d3 = conv_block(d3, filters * 2)\n",
    "    \n",
    "    d4 = UpSampling2D()(d3)\n",
    "    d4 = Concatenate()([d4, e1])\n",
    "    d4 = conv_block(d4, filters)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Conv2D(filters=num_classes,\n",
    "                     kernel_size=1,\n",
    "                     padding='same',\n",
    "                     activation='sigmoid')(d4)\n",
    "    \n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e425feb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:40:27.174920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 20:40:27.184206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 20:40:27.185112: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 20:40:27.186205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 20:40:27.186879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 20:40:27.187756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 20:40:27.188522: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 20:40:27.746587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 20:40:27.747383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 20:40:27.748136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 20:40:27.748850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22310 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = build_Unet(filters=32)  # original U-Net: 64 filters\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3),  # Define optimizer and learning rate\n",
    "              loss=dice_loss,                      # Dice loss function\n",
    "              metrics=[iou_score])     # Intersection over Union (IoU) & Dice score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be235a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_scheduler(epoch, lr):\n",
    "    \"\"\"\n",
    "    Learning rate scheduler.\n",
    "    \"\"\"\n",
    "    if epoch < 20:\n",
    "        return 1e-3\n",
    "    elif epoch < 40:\n",
    "        return 1e-4\n",
    "    elif epoch < 60:\n",
    "        return 1e-5\n",
    "    else:\n",
    "        return lr * np.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d9b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X_train, Y_train = load_train_videos(path_training_vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0135beee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:40:58.680383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200\n",
      "2023-04-24 20:40:59.361282: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-24 20:41:01.639245: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f2ec67d7b00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-24 20:41:01.639265: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2023-04-24 20:41:01.641928: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-24 20:41:01.683651: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-24 20:41:01.719440: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-04-24 20:41:03.291836: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-24 20:41:03.291856: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/284 [============================>.] - ETA: 0s - loss: 0.9863 - iou_score: 0.0070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:42:12.368003: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-24 20:42:12.368023: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "284/284 [==============================] - ETA: 0s - loss: 0.9862 - iou_score: 0.0070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:42:18.631117: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.76GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-24 20:42:18.631136: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.76GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 83s 253ms/step - loss: 0.9862 - iou_score: 0.0070 - val_loss: 0.9927 - val_iou_score: 0.0040 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "284/284 [==============================] - 68s 241ms/step - loss: 0.9246 - iou_score: 0.0394 - val_loss: 0.9536 - val_iou_score: 0.0247 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "284/284 [==============================] - 69s 242ms/step - loss: 0.9036 - iou_score: 0.0509 - val_loss: 0.9391 - val_iou_score: 0.0328 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8953 - iou_score: 0.0555 - val_loss: 0.9335 - val_iou_score: 0.0359 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8872 - iou_score: 0.0601 - val_loss: 0.9494 - val_iou_score: 0.0264 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8914 - iou_score: 0.0579 - val_loss: 0.9136 - val_iou_score: 0.0468 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "284/284 [==============================] - 69s 244ms/step - loss: 0.8789 - iou_score: 0.0648 - val_loss: 0.9492 - val_iou_score: 0.0276 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8669 - iou_score: 0.0716 - val_loss: 0.9460 - val_iou_score: 0.0296 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8667 - iou_score: 0.0718 - val_loss: 0.9222 - val_iou_score: 0.0421 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8700 - iou_score: 0.0699 - val_loss: 0.9139 - val_iou_score: 0.0474 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8617 - iou_score: 0.0747 - val_loss: 0.9501 - val_iou_score: 0.0265 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8635 - iou_score: 0.0737 - val_loss: 0.9156 - val_iou_score: 0.0457 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8587 - iou_score: 0.0764 - val_loss: 0.9042 - val_iou_score: 0.0528 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8629 - iou_score: 0.0740 - val_loss: 0.9318 - val_iou_score: 0.0368 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8541 - iou_score: 0.0790 - val_loss: 0.9146 - val_iou_score: 0.0470 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8553 - iou_score: 0.0784 - val_loss: 0.9289 - val_iou_score: 0.0382 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8577 - iou_score: 0.0770 - val_loss: 0.9173 - val_iou_score: 0.0454 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8528 - iou_score: 0.0798 - val_loss: 0.9274 - val_iou_score: 0.0397 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8511 - iou_score: 0.0809 - val_loss: 0.9197 - val_iou_score: 0.0437 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8585 - iou_score: 0.0766 - val_loss: 0.9268 - val_iou_score: 0.0397 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8424 - iou_score: 0.0860 - val_loss: 0.9025 - val_iou_score: 0.0536 - lr: 1.0000e-04\n",
      "Epoch 22/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8271 - iou_score: 0.0951 - val_loss: 0.9023 - val_iou_score: 0.0537 - lr: 1.0000e-04\n",
      "Epoch 23/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8217 - iou_score: 0.0984 - val_loss: 0.9026 - val_iou_score: 0.0536 - lr: 1.0000e-04\n",
      "Epoch 24/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8173 - iou_score: 0.1012 - val_loss: 0.9038 - val_iou_score: 0.0529 - lr: 1.0000e-04\n",
      "Epoch 25/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8146 - iou_score: 0.1028 - val_loss: 0.9038 - val_iou_score: 0.0531 - lr: 1.0000e-04\n",
      "Epoch 26/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8135 - iou_score: 0.1035 - val_loss: 0.9013 - val_iou_score: 0.0547 - lr: 1.0000e-04\n",
      "Epoch 27/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8112 - iou_score: 0.1049 - val_loss: 0.9023 - val_iou_score: 0.0541 - lr: 1.0000e-04\n",
      "Epoch 28/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8099 - iou_score: 0.1057 - val_loss: 0.9039 - val_iou_score: 0.0535 - lr: 1.0000e-04\n",
      "Epoch 29/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8091 - iou_score: 0.1062 - val_loss: 0.9047 - val_iou_score: 0.0530 - lr: 1.0000e-04\n",
      "Epoch 30/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8072 - iou_score: 0.1072 - val_loss: 0.8995 - val_iou_score: 0.0558 - lr: 1.0000e-04\n",
      "Epoch 31/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8048 - iou_score: 0.1089 - val_loss: 0.8997 - val_iou_score: 0.0558 - lr: 1.0000e-04\n",
      "Epoch 32/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8050 - iou_score: 0.1087 - val_loss: 0.8991 - val_iou_score: 0.0560 - lr: 1.0000e-04\n",
      "Epoch 33/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8033 - iou_score: 0.1096 - val_loss: 0.8966 - val_iou_score: 0.0573 - lr: 1.0000e-04\n",
      "Epoch 34/80\n",
      "284/284 [==============================] - 69s 243ms/step - loss: 0.8022 - iou_score: 0.1104 - val_loss: 0.8968 - val_iou_score: 0.0571 - lr: 1.0000e-04\n",
      "Epoch 35/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=Y_train, epochs=80,\n",
    "                    callbacks=[LearningRateScheduler(schedule=exp_scheduler, verbose=0)], \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e08c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3e2c1bbe50>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"reference_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666a76e",
   "metadata": {},
   "source": [
    "## Apply the model to our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb03355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_data(path):\n",
    "    \"\"\"\n",
    "    This function returns all validation videos and the annotations as binary masks (1 at the positions where a Hexbug is located).\n",
    "    All frames are resized and normalized. \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    org_shapes = []\n",
    "    file_names = []\n",
    "    \n",
    "    for vid in os.listdir(path):\n",
    "        path = Path(path)\n",
    "        if \".mp4\" in vid:\n",
    "            with open(path / vid.replace(\"mp4\", \"traco\")) as f:\n",
    "                annotations = json.load(f)['rois']\n",
    "                  \n",
    "            cap = cv2.VideoCapture(str(path / vid))\n",
    "            ret, frame = cap.read()     \n",
    "            org_shape = frame.shape\n",
    "            \n",
    "            file_names.append(path / vid.replace(\"mp4\", \"traco\"))\n",
    "            org_shapes.append(org_shape)\n",
    "            \n",
    "            X_ = []\n",
    "            while ret:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                # Resize the frame to the target size using bilinear interpolation\n",
    "                resized_frame = cv2.resize(frame, target_shape, interpolation=cv2.INTER_LINEAR)\n",
    "                \n",
    "                # Normalize to zero mean and unit variance\n",
    "                normalized_frame = (resized_frame.astype('float32') / 255.0 - 0.5) / 0.5\n",
    "                \n",
    "                # Append to lists\n",
    "                X_.append(normalized_frame)\n",
    "                \n",
    "                ret, frame = cap.read()  # read next frame\n",
    "            \n",
    "            X.append(np.asarray(X_))           \n",
    "    \n",
    "    return X, org_shapes, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f8fbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, org_shapes_test, file_names_test = load_validation_data(\"leaderboard_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01ec0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_points_from_predictions(pred, org_shape):\n",
    "    \"\"\"\n",
    "    This function finds cluster where a Hexbug is detected. It resizes the found positions back to fit the original frame shape.\n",
    "    \"\"\"\n",
    "    points = np.transpose(np.where(pred > 0.01))\n",
    "    if len(points) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Perform clustering\n",
    "    eps = 10\n",
    "    min_samples = 1\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    dbscan.fit(points)\n",
    "    labels = dbscan.labels_\n",
    "    \n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    final_points = []\n",
    "    for i in range(n_clusters):\n",
    "        random_point = np.random.choice(np.where(labels == i)[0])\n",
    "        random_point = points[random_point]\n",
    "        random_point[0] = int(random_point[0] * org_shape[0] // target_shape[0])\n",
    "        random_point[1] = int(random_point[1] * org_shape[1] // target_shape[1])\n",
    "    \n",
    "        final_points.append(random_point)\n",
    "    \n",
    "    return final_points[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92ce53c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('leaderboard_data/test0005.traco'),\n",
       " PosixPath('leaderboard_data/test0003.traco'),\n",
       " PosixPath('leaderboard_data/test0001.traco'),\n",
       " PosixPath('leaderboard_data/test0002.traco'),\n",
       " PosixPath('leaderboard_data/test0004.traco')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca358bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from export_tool import traco_to_csv, from_array_to_dict, save_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62ed0d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 61ms/step\n",
      "Saving to csv\n",
      "Done\n",
      "4/4 [==============================] - 0s 61ms/step\n",
      "Saving to csv\n",
      "Done\n",
      "4/4 [==============================] - 0s 61ms/step\n",
      "Saving to csv\n",
      "Done\n",
      "4/4 [==============================] - 0s 61ms/step\n",
      "Saving to csv\n",
      "Done\n",
      "4/4 [==============================] - 0s 61ms/step\n",
      "Saving to csv\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for idx, x in enumerate(X_test):    \n",
    "    # Predict all frames of one video\n",
    "    preds = model.predict(x)\n",
    "    \n",
    "    org_shape = org_shapes_test[idx]\n",
    "    file_name = file_names_test[idx]\n",
    "    \n",
    "    # Get final predicted points for each frame\n",
    "    n_hexbugs = None\n",
    "    previous_coords = None\n",
    "    results = []\n",
    "    for frame_idx, pred in enumerate(preds):\n",
    "        pred = np.squeeze(pred)\n",
    "        coords = get_final_points_from_predictions(pred, org_shape)\n",
    "        \n",
    "        if n_hexbugs is None:\n",
    "            n_hexbugs = len(coords)\n",
    "            if n_hexbugs == 0:\n",
    "                n_hexbugs = 1\n",
    "\n",
    "        for i in range(n_hexbugs):\n",
    "            try:\n",
    "                results = from_array_to_dict([frame_idx, i, coords[i][1], coords[i][0]], results)\n",
    "            except:\n",
    "                results = from_array_to_dict([frame_idx, i, 0, 0], results)\n",
    "            \n",
    "    save_list(results, str(file_name).replace(\".traco\", \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f99ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
